{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272c232c",
   "metadata": {},
   "source": [
    "# CLUSTERING\n",
    "\n",
    "* grouping of data points\n",
    "\n",
    "### Algorithm for K-Means\n",
    "- Step1: randomly pick K points to place k centroids\n",
    "- Step2: Assign all the data pointsto the centroid by distance. The closest centroid to a point is the one it is assigned to\n",
    "- Step3: Avg all the points belonging to each centriod to find the middle of those clusters(center of mass). Place the coressponding centrids into that position.\n",
    "- Step4: Reassign every point to the closest centroid.\n",
    "- Step5: Repeat steps 3-4 until no point changes wich centroid it belongs to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04122e0b",
   "metadata": {},
   "source": [
    "## Hidden Markov Models\n",
    "- finites set of states, each is associated with prob distribution\n",
    "- trasitions among states are governed by transition probabilities\n",
    "- these prob are used to predict future states/events\n",
    "\n",
    "#### To create HMM we need:\n",
    "- states\n",
    "- obsevation distribution\n",
    "- Transistion distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468eff1",
   "metadata": {},
   "source": [
    "## imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d49fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow_probability\n",
      "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-win_amd64.whl (101 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow_probability) (1.16.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\anaconda3\\lib\\site-packages (from tensorflow_probability) (0.4.0)\n",
      "Requirement already satisfied: absl-py in c:\\anaconda3\\lib\\site-packages (from tensorflow_probability) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\anaconda3\\lib\\site-packages (from tensorflow_probability) (1.21.5)\n",
      "Requirement already satisfied: decorator in c:\\anaconda3\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\anaconda3\\lib\\site-packages (from tensorflow_probability) (2.0.0)\n",
      "Installing collected packages: dm-tree, tensorflow-probability\n",
      "Successfully installed dm-tree-0.1.8 tensorflow-probability-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_probability\n",
    "!pip install tensorflow_probability==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2aaecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f74087",
   "metadata": {},
   "source": [
    "#### weather model\n",
    "- cold days encoded by 0,hot days encoded by 1\n",
    "- 1st day in our seq has an 80% chance of being cold\n",
    "- a cold day has 30% chance of being followed by a hot day\n",
    "- a hot day has a 20% chance of being followed by a cold day\n",
    "- on each day temp is normally distributed with mean and std deviation 0 & 5 on a cold day and 15 & 10  on hot day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0c267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the distribution variables\n",
    "tfd = tfp.distributions\n",
    "initial_distribution = tfd.Categorical(probs=[0.8, 0.2]) # 2nd point\n",
    "transition_distribution = tfd.Categorical(probs=[[0.7,0.3],\n",
    "                                                [0.2,0.8]]) # 3, 4 points\n",
    "observation_distribution = tfd.Normal(loc=[0.,15.], scale=[5.,10.]) # loc repr the mean and scale repr std deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5e3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating HMM model\n",
    "\n",
    "model = tfd.HiddenMarkovModel(\n",
    "        initial_distribution=initial_distribution,\n",
    "        transition_distribution=transition_distribution,\n",
    "        observation_distribution=observation_distribution,\n",
    "        num_steps=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8eefecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.        5.9999995 7.4999995 8.25      8.625     8.812501  8.90625  ]\n"
     ]
    }
   ],
   "source": [
    "# to get the expected temperatures on each day\n",
    "\n",
    "mean = model.mean() # partially defined tensors\n",
    "\n",
    "# to run a session in new tf\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(mean.numpy()) # gives the expected temp on each day\n",
    "    \n",
    "# if we re run the model, the prob will remain same and hence we get the op as same(no training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002c1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
